{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Programming â€“ Deep Learning with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blog: http://deeplizard.com/learn/video/v5cngxo4mIg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Neural Networks and Deep Learning with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance of Data in Deep Learning - Fashion MNIST for Artificial Intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blog: http://deeplizard.com/learn/video/EqpzfvxBx30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL with the PyTorch ```Dataset``` and ```DataLoader``` classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blog: http://deeplizard.com/learn/video/8n-TGaBZnk4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n",
      "0.3.0\n"
     ]
    }
   ],
   "source": [
    "# Check blog post on deeplizard.com for any version related updates\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data'\n",
    "    ,train=True\n",
    "    ,download=True\n",
    "    ,transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Datasets and DataLoaders - Training Set Exploration for Deep Learning and AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blog: http://deeplizard.com/learn/video/mUueSPmcOBc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data'\n",
    "    ,train=True\n",
    "    ,download=True\n",
    "    ,transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.set_printoptions(linewidth=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 0, 0,  ..., 3, 0, 5])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.targets.bincount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(label) # Note that this used to be a tensor as well. Changed as of torchvision version 0.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the release notes for this change: https://github.com/pytorch/vision/releases/tag/v0.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(label).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image.squeeze(), cmap='gray')\n",
    "print('label:', label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with the data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 28, 28])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid dimensions for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-48029e29aabe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#plt.imshow(np.transpose(grid, (1,2,0)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'labels:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   2697\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2698\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[1;32m-> 2699\u001b[1;33m         None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2700\u001b[0m     \u001b[0msci\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2701\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1808\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1810\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5492\u001b[0m                               resample=resample, **kwargs)\n\u001b[0;32m   5493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5494\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5495\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5496\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    636\u001b[0m         if not (self._A.ndim == 2\n\u001b[0;32m    637\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m--> 638\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid dimensions for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid = torchvision.utils.make_grid(images, nrow=10)\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(np.transpose(grid, (1,2,0)))\n",
    "plt.imshow(grid)\n",
    "\n",
    "print('labels:', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "how_many_to_plot = 20\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size=1, shuffle=True\n",
    ")\n",
    "\n",
    "mapping = {\n",
    "    0:'Top', 1:'Trousers', 2:'Pullover', 3:'Dress', 4:'Coat'\n",
    "    ,5:'Sandal', 6:'Shirt', 7:'Sneaker', 8:'Bag', 9:'Ankle Boot'\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(50,50))\n",
    "for i, batch in enumerate(train_loader, start=1):\n",
    "    image, label = batch\n",
    "    plt.subplot(10,10,i)\n",
    "    fig = plt.imshow(image.reshape(28,28), cmap='gray')\n",
    "    fig.axes.get_xaxis().set_visible(False)\n",
    "    fig.axes.get_yaxis().set_visible(False)\n",
    "    plt.title(mapping[label.item()], fontsize=28)\n",
    "    if (i >= how_many_to_plot): break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build PyTorch CNN - Object Oriented Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link: http://deeplizard.com/learn/video/k4jY9L8H89U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object Oriented Programming Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lizard:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        \n",
    "    def set_name(self, name):\n",
    "        self.name = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lizard = Lizard('deep')\n",
    "print(lizard.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lizard.set_name('lizard')\n",
    "print(lizard.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self):\n",
    "        self.layer = None\n",
    "        \n",
    "    def forward(self, t):\n",
    "        t = self.layer(t)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        #implement the forward pass\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network()\n",
    "network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch CNN Weights - Learnable Parameters in Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link: http://deeplizard.com/learn/video/stWU37L91Yc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        #implement the forward pass\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network():#nn.Module):\n",
    "    def __init__(self):\n",
    "        #super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        #implement the forward pass\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network():#nn.Module):\n",
    "    def __init__(self):\n",
    "        #super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        #implement the forward pass\n",
    "        return t\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"lizardnet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting model back to original\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        #implement the forward pass\n",
    "        return t\n",
    "    \n",
    "network = Network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing the Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "network.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing the Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "network.conv1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.conv1.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.conv2.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.conv2.weight[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.fc1.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.fc2.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "network.out.weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the linear layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.fc1.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.fc2.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "network.out.weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = torch.tensor([1,2,3,4], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_matrix = torch.tensor([\n",
    "    [1,2,3,4],\n",
    "    [2,3,4,5],\n",
    "    [3,4,5,6]\n",
    "], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weight_matrix.matmul(in_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing the Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for param in network.parameters():\n",
    "    print(param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in network.named_parameters():\n",
    "    print(name, '\\t\\t', param.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Callable Neural Networks â€“ Linear Layer in Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = torch.tensor([1,2,3,4], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_matrix = torch.tensor([\n",
    "    [1,2,3,4],\n",
    "    [2,3,4,5],\n",
    "    [3,4,5,6]\n",
    "], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "weight_matrix.matmul(in_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = nn.Linear(in_features=4, out_features=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.weight = nn.Parameter(weight_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fc(in_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = nn.Linear(in_features=4, out_features=3, bias=False)\n",
    "fc.weight = nn.Parameter(weight_matrix)\n",
    "fc(in_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build PyTorch CNN - Forward Method Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=12 * 4 * 4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        # (1) input layer\n",
    "        t = t\n",
    "        \n",
    "        # (2) hidden conv layer\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        # (3) hidden conv layer\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        # (4) hidden linear layer\n",
    "        t = t.reshape(-1, 12 * 4 * 4)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # (5) hidden linear layer\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # (6) output layer\n",
    "        t = self.out(t)\n",
    "        #t = F.softmax(t, dim=1)\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Propagation Explained - Pass Image to PyTorch Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "torch.set_printoptions(linewidth=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data'\n",
    "    ,train=True\n",
    "    ,download=True\n",
    "    ,transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        t = F.relu(self.conv1(t))\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        t = F.relu(self.conv2(t))\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        t = F.relu(self.fc1(t.reshape(-1, 12*4*4)))\n",
    "        t = F.relu(self.fc2(t))\n",
    "        t = self.out(t)\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells PyTorch to disable gradient tracking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Passing a single image to the network*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(train_set))\n",
    "image, label = sample\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks usually accept batches of inputs.  \n",
    "Thus, the image tensor's shape needs to be in the form (batch_size Ã— in_channels Ã— height Ã— width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image.unsqueeze(0).shape # This gives us a batch with size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = network(image.unsqueeze(0)) # image shape needs to be (batch_size Ã— in_channels Ã— H Ã— W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.softmax(pred, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.softmax(pred, dim=1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different instances of our network have different weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1(image.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2(image.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Batch Processing - Pass Image Batch to PyTorch Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "torch.set_printoptions(linewidth=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check blog post on deeplizard.com for any version related updates\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data'\n",
    "    ,train=True\n",
    "    ,download=True\n",
    "    ,transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        # (1) input layer\n",
    "        t = t\n",
    "        \n",
    "        # (2) hidden conv layer\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        # (3) hidden conv layer\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        # (4) hidden linear layer\n",
    "        t = t.reshape(-1, 12 * 4 * 4)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # (5) hidden linear layer\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # (6) output layer\n",
    "        t = self.out(t)\n",
    "        #t = F.softmax(t, dim=1)\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(train_set, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch = next(iter(data_loader))\n",
    "images, labels = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = network(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Checking batch predictions aginst the label tensor*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.argmax(dim=1).eq(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds.argmax(dim=1).eq(labels).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_num_correct(preds, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a PyTorch CNN - Calculate Loss, Gradient & Update Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "torch.set_printoptions(linewidth=120) # Display options for output\n",
    "torch.set_grad_enabled(True) # Already on by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=12 * 4 * 4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        # (1) input layer\n",
    "        t = t\n",
    "        \n",
    "        # (2) hidden conv layer\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        # (3) hidden conv layer\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        # (4) hidden linear layer\n",
    "        t = t.reshape(-1, 12 * 4 * 4)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # (5) hidden linear layer\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # (6) output layer\n",
    "        t = self.out(t)\n",
    "        #t = F.softmax(t, dim=1)\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data'\n",
    "    ,train=True\n",
    "    ,download=True\n",
    "    ,transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100)\n",
    "batch = next(iter(train_loader))\n",
    "images, labels = batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = network(images)\n",
    "loss = F.cross_entropy(preds, labels) # Calculating the loss\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(network.conv1.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss.backward() # Calculating the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "network.conv1.weight.grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.conv1.weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating the Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(network.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_num_correct(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step() # Updating the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = network(images)\n",
    "loss = F.cross_entropy(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_num_correct(preds, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Training Loop - Neural Network Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "torch.set_printoptions(linewidth=120) # Display options for output\n",
    "torch.set_grad_enabled(True) # Already on by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=12 * 4 * 4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "       \n",
    "        t = F.relu(self.conv1(t))\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        t = F.relu(self.conv2(t))\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        t = t.reshape(-1, 12 * 4 * 4)\n",
    "        t = F.relu(self.fc1(t))\n",
    "        \n",
    "        t = F.relu(self.fc2(t))\n",
    "        \n",
    "        t = self.out(t)\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data'\n",
    "    ,train=True\n",
    "    ,download=True\n",
    "    ,transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with a single batch: Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network()\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100)\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.01)\n",
    "\n",
    "batch = next(iter(train_loader)) # Get Batch\n",
    "images, labels = batch\n",
    "\n",
    "preds = network(images) # Pass Batch\n",
    "loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
    "\n",
    "loss.backward() # Calculate Gradients\n",
    "optimizer.step() # Update Weights\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "print('loss1:', loss.item())\n",
    "preds = network(images)\n",
    "loss = F.cross_entropy(preds, labels)\n",
    "print('loss2:', loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with all batches: A single epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network()\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100)\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.01)\n",
    "\n",
    "total_loss = 0\n",
    "total_correct = 0\n",
    "\n",
    "for batch in train_loader: # Get Batch\n",
    "    images, labels = batch \n",
    "\n",
    "    preds = network(images) # Pass Batch\n",
    "    loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward() # Calculate Gradients\n",
    "    optimizer.step() # Update Weights\n",
    "\n",
    "    total_loss += loss.item()\n",
    "    total_correct += get_num_correct(preds, labels)\n",
    "    \n",
    "print(\"epoch:\", 0, \"total_correct:\", total_correct, \"loss:\", total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_correct / len(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with multiple epochs: The complete training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "network = Network()\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100)\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(5):\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for batch in train_loader: # Get Batch\n",
    "        images, labels = batch \n",
    "\n",
    "        preds = network(images) # Pass Batch\n",
    "        loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # Calculate Gradients\n",
    "        optimizer.step() # Update Weights\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "    print(\"epoch:\", epoch, \"total_correct:\", total_correct, \"loss:\", total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_correct / len(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing CNN Results - Building and Plotting a Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_set.targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting predictions for the entire training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_preds(model, loader):\n",
    "    all_preds = torch.tensor([])\n",
    "    for batch in loader:\n",
    "        images, labels = batch\n",
    "\n",
    "        preds = model(images)\n",
    "        all_preds = torch.cat(\n",
    "            (all_preds, preds)\n",
    "            ,dim=0\n",
    "        )\n",
    "    return all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_loader = torch.utils.data.DataLoader(train_set, batch_size=10000)\n",
    "train_preds = get_all_preds(network, prediction_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_preds.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    prediction_loader = torch.utils.data.DataLoader(train_set, batch_size=10000)\n",
    "    train_preds = get_all_preds(network, prediction_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_preds.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds_correct = get_num_correct(train_preds, train_set.targets)\n",
    "\n",
    "print('total correct:', preds_correct)\n",
    "print('accuracy:', preds_correct / len(train_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stacked = torch.stack(\n",
    "    (\n",
    "        train_set.targets\n",
    "        ,train_preds.argmax(dim=1)\n",
    "    )\n",
    "    ,dim=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cmt = torch.zeros(10,10, dtype=torch.int32)\n",
    "cmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in stacked:\n",
    "    tl, pl = p.tolist()\n",
    "    cmt[tl, pl] = cmt[tl, pl] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from resources.plotcm import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(train_set.targets, train_preds.argmax(dim=1))\n",
    "print(type(cm))\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "names = ('T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot')\n",
    "plt.figure(figsize=(10,10))\n",
    "plot_confusion_matrix(cmt, names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TensorBoard with PyTorch - Deep Learning Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "torch.set_printoptions(linewidth=120) # Display options for output\n",
    "torch.set_grad_enabled(True) # Already on by default\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=12 * 4 * 4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "       \n",
    "        t = F.relu(self.conv1(t))\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        t = F.relu(self.conv2(t))\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        t = t.flatten(start_dim=1)\n",
    "        t = F.relu(self.fc1(t))\n",
    "        \n",
    "        t = F.relu(self.fc2(t))\n",
    "        \n",
    "        t = self.out(t)\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data'\n",
    "    ,train=True\n",
    "    ,download=True\n",
    "    ,transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting out with TensorBoard (Network Graph and Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = SummaryWriter()\n",
    "\n",
    "network = Network()\n",
    "images, labels = next(iter(train_loader))\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "tb.add_image('images', grid)\n",
    "tb.add_graph(network, images)\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Training Loop Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network()\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100, shuffle=True)\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1):\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    \n",
    "    for batch in train_loader: # Get Batch\n",
    "        images, labels = batch \n",
    "\n",
    "        preds = network(images) # Pass Batch\n",
    "        loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # Calculate Gradients\n",
    "        optimizer.step() # Update Weights\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "    print(\"epoch\", epoch, \"total_correct:\", total_correct, \"loss:\", total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network()\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100, shuffle=True)\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.01)\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "tb = SummaryWriter()\n",
    "tb.add_image('images', grid)\n",
    "tb.add_graph(network, images)\n",
    "\n",
    "for epoch in range(10):\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    \n",
    "    for batch in train_loader: # Get Batch\n",
    "        images, labels = batch \n",
    "\n",
    "        preds = network(images) # Pass Batch\n",
    "        loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # Calculate Gradients\n",
    "        optimizer.step() # Update Weights\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_correct += get_num_correct(preds, labels)\n",
    "    \n",
    "    tb.add_scalar('Loss', total_loss, epoch)\n",
    "    tb.add_scalar('Number Correct', total_correct, epoch)\n",
    "    tb.add_scalar('Accuracy', total_correct / len(train_set), epoch)\n",
    "    \n",
    "    tb.add_histogram('conv1.bias', network.conv1.bias, epoch)\n",
    "    tb.add_histogram('conv1.weight', network.conv1.weight, epoch)\n",
    "    tb.add_histogram('conv1.weight.grad', network.conv1.weight.grad, epoch)\n",
    "    \n",
    "    print(\"epoch\", epoch, \"total_correct:\", total_correct, \"loss:\", total_loss)\n",
    "    \n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  CNN Training Hyperparameters - Nerual Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network()\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100, shuffle=True)\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.01)\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "tb = SummaryWriter()\n",
    "tb.add_image('images', grid)\n",
    "tb.add_graph(network, images)\n",
    "\n",
    "for epoch in range(5):\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    \n",
    "    for batch in train_loader: # Get Batch\n",
    "        images, labels = batch \n",
    "\n",
    "        preds = network(images) # Pass Batch\n",
    "        loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # Calculate Gradients\n",
    "        optimizer.step() # Update Weights\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_correct += get_num_correct(preds, labels)\n",
    "    \n",
    "    tb.add_scalar('Loss', total_loss, epoch)\n",
    "    tb.add_scalar('Number Correct', total_correct, epoch)\n",
    "    tb.add_scalar('Accuracy', total_correct / len(train_set), epoch)\n",
    "    \n",
    "    #tb.add_histogram('conv1.bias', network.conv1.bias, epoch)\n",
    "    #tb.add_histogram('conv1.weight', network.conv1.weight, epoch)\n",
    "    #tb.add_histogram('conv1.weight.grad', network.conv1.weight.grad, epoch)\n",
    "    \n",
    "    for name, weight in network.named_parameters():\n",
    "        tb.add_histogram(name, weight, epoch)\n",
    "        tb.add_histogram(f'{name}.grad', weight.grad, epoch)\n",
    "    \n",
    "    print(\"epoch\", epoch, \"total_correct:\", total_correct, \"loss:\", total_loss)\n",
    "    \n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, weight in network.named_parameters():\n",
    "    print(name, weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, weight in network.named_parameters():\n",
    "    print(f'{name}.grad', weight.grad.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameterize Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "lr = 0.01\n",
    "\n",
    "network = Network()\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
    "optimizer = optim.Adam(network.parameters(), lr=lr)\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "comment = f' batch_size={batch_size} lr={lr}'\n",
    "tb = SummaryWriter(comment=comment)\n",
    "tb.add_image('images', grid)\n",
    "tb.add_graph(network, images)\n",
    "\n",
    "for epoch in range(2):\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    for batch in train_loader:\n",
    "        images, labels = batch # Get Batch\n",
    "        preds = network(images) # Pass Batch\n",
    "        loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
    "        optimizer.zero_grad() # Zero Gradients\n",
    "        loss.backward() # Calculate Gradients\n",
    "        optimizer.step() # Update Weights\n",
    "\n",
    "        total_loss += loss.item() * batch_size\n",
    "        total_correct += get_num_correct(preds, labels)\n",
    "    \n",
    "    tb.add_scalar('Loss', total_loss, epoch)\n",
    "    tb.add_scalar('Number Correct', total_correct, epoch)\n",
    "    tb.add_scalar('Accuracy', total_correct / len(train_set), epoch)\n",
    "    \n",
    "    for name, param in network.named_parameters():\n",
    "        tb.add_histogram(name, param, epoch)\n",
    "        tb.add_histogram(f'{name}.grad', param.grad, epoch)\n",
    "    \n",
    "    print(\"epoch\", epoch, \"total_correct:\", total_correct, \"loss:\", total_loss)  \n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating on Parameter Values Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_list = [100, 1000, 10000]\n",
    "lr_list = [.01, .001, .0001, .00001]\n",
    "\n",
    "for batch_size in batch_size_list:\n",
    "    for lr in lr_list:\n",
    "        network = Network()\n",
    "        train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
    "        optimizer = optim.Adam(network.parameters(), lr=lr)\n",
    "\n",
    "        images, labels = next(iter(train_loader))\n",
    "        grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "        comment=f' batch_size={batch_size} lr={lr}'\n",
    "        tb = SummaryWriter(comment=comment)\n",
    "        tb.add_image('images', grid)\n",
    "        tb.add_graph(network, images)\n",
    "\n",
    "        for epoch in range(1):\n",
    "            total_loss = 0\n",
    "            total_correct = 0\n",
    "            for batch in train_loader:\n",
    "                images, labels = batch # Get Batch\n",
    "                preds = network(images) # Pass Batch\n",
    "                loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
    "                optimizer.zero_grad() # Zero Gradients\n",
    "                loss.backward() # Calculate Gradients\n",
    "                optimizer.step() # Update Weights\n",
    "\n",
    "                total_loss += loss.item() * batch_size\n",
    "                total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "            tb.add_scalar('Loss', total_loss, epoch)\n",
    "            tb.add_scalar('Number Correct', total_correct, epoch)\n",
    "            tb.add_scalar('Accuracy', total_correct / len(train_set), epoch)\n",
    "\n",
    "            for name, param in network.named_parameters():\n",
    "                tb.add_histogram(name, param, epoch)\n",
    "                tb.add_histogram(f'{name}.grad', param.grad, epoch)\n",
    "\n",
    "            print(\"epoch\", epoch, \"total_correct:\", total_correct, \"loss:\", total_loss)  \n",
    "        tb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating on Parameter Values Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict(\n",
    "    lr = [.01, .001]\n",
    "    ,batch_size = [10, 100, 1000]\n",
    "    ,shuffle = [True, False]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_values = [v for v in parameters.values()]\n",
    "param_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for lr, batch_size, shuffle in product(*param_values): \n",
    "    print (lr, batch_size, shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr, batch_size, shuffle in product(*param_values): \n",
    "    comment = f' batch_size={batch_size} lr={lr} shuffle={shuffle}'\n",
    "    network = Network()\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=shuffle)\n",
    "    optimizer = optim.Adam(network.parameters(), lr=lr)\n",
    "    images, labels = next(iter(train_loader))\n",
    "    grid = torchvision.utils.make_grid(images)\n",
    "    tb = SummaryWriter(comment=comment)\n",
    "    tb.add_image('images', grid)\n",
    "    tb.add_graph(network, images)\n",
    "    for epoch in range(25):\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        for batch in train_loader:\n",
    "            images, labels = batch # Get Batch\n",
    "            preds = network(images) # Pass Batch\n",
    "            loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
    "            optimizer.zero_grad() # Zero Gradients\n",
    "            loss.backward() # Calculate Gradients\n",
    "            optimizer.step() # Update Weights\n",
    "\n",
    "            total_loss += loss.item() * batch_size\n",
    "            total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "        tb.add_scalar('Loss', total_loss, epoch)\n",
    "        tb.add_scalar('Number Correct', total_correct, epoch)\n",
    "        tb.add_scalar('Accuracy', total_correct / len(train_set), epoch)\n",
    "\n",
    "        for name, param in network.named_parameters():\n",
    "            tb.add_histogram(name, param, epoch)\n",
    "            tb.add_histogram(f'{name}.grad', param.grad, epoch)\n",
    "\n",
    "        print(\"epoch\", epoch, \"total_correct:\", total_correct, \"loss:\", total_loss)  \n",
    "    tb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack vs Concat in PyTorch, TensorFlow & NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor([1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.unsqueeze(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.unsqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t1.shape)\n",
    "print(t1.unsqueeze(dim=0).shape)\n",
    "print(t1.unsqueeze(dim=1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch: Stack vs Cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor([1,1,1])\n",
    "t2 = torch.tensor([2,2,2])\n",
    "t3 = torch.tensor([3,3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.cat(\n",
    "    (t1,t2,t3)\n",
    "    ,dim=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.stack(\n",
    "    (t1,t2,t3)\n",
    "    ,dim=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.cat(\n",
    "    (\n",
    "         t1.unsqueeze(0)\n",
    "        ,t2.unsqueeze(0)\n",
    "        ,t3.unsqueeze(0)\n",
    "    )\n",
    "    ,dim=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.stack(\n",
    "    (t1,t2,t3)\n",
    "    ,dim=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.cat(\n",
    "    ( \n",
    "        t1.unsqueeze(1)\n",
    "        ,t2.unsqueeze(1)\n",
    "        ,t3.unsqueeze(1)\n",
    "    )\n",
    "    ,dim=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking along the second axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "t1 = torch.tensor([1,1,1])\n",
    "t2 = torch.tensor([2,2,2])\n",
    "t3 = torch.tensor([3,3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow: Stack vs Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = tf.constant([1,1,1])\n",
    "t2 = tf.constant([2,2,2])\n",
    "t3 = tf.constant([3,3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.concat(\n",
    "    (t1,t2,t3)\n",
    "    ,axis=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.stack(\n",
    "    (t1,t2,t3)\n",
    "    ,axis=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.concat(\n",
    "    (\n",
    "         tf.expand_dims(t1, 0)\n",
    "        ,tf.expand_dims(t2, 0)\n",
    "        ,tf.expand_dims(t3, 0)\n",
    "    )\n",
    "    ,axis=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.stack(\n",
    "    (t1,t2,t3)\n",
    "    ,axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.concat(\n",
    "    (\n",
    "         tf.expand_dims(t1, 1)\n",
    "        ,tf.expand_dims(t2, 1)\n",
    "        ,tf.expand_dims(t3, 1)\n",
    "    )    \n",
    "    ,axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy: Stack vs Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = np.array([1,1,1])\n",
    "t2 = np.array([2,2,2])\n",
    "t3 = np.array([3,3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate(\n",
    "    (t1,t2,t3)\n",
    "    ,axis=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(\n",
    "    (t1,t2,t3)\n",
    "    ,axis=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate(\n",
    "    (\n",
    "         np.expand_dims(t1, 0)\n",
    "        ,np.expand_dims(t2, 0)\n",
    "        ,np.expand_dims(t3, 0)\n",
    "    )\n",
    "    ,axis=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(\n",
    "    (t1,t2,t3)\n",
    "    ,axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.concatenate(\n",
    "    (\n",
    "         np.expand_dims(t1, 1)\n",
    "        ,np.expand_dims(t2, 1)\n",
    "        ,np.expand_dims(t3, 1)\n",
    "    )\n",
    "    ,axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real World Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining images into a single batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "t1 = torch.zeros(3,28,28)\n",
    "t2 = torch.zeros(3,28,28)\n",
    "t3 = torch.zeros(3,28,28)\n",
    "torch.stack(\n",
    "    (t1,t2,t3)\n",
    "    ,dim=0\n",
    ").shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining batches into a single batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "t1 = torch.zeros(1,3,28,28)\n",
    "t2 = torch.zeros(1,3,28,28)\n",
    "t3 = torch.zeros(1,3,28,28)\n",
    "torch.cat(\n",
    "    (t1,t2,t3)\n",
    "    ,dim=0\n",
    ").shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining images with an existing batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "batch = torch.zeros(3,3,28,28)\n",
    "t1 = torch.zeros(3,28,28)\n",
    "t2 = torch.zeros(3,28,28)\n",
    "t3 = torch.zeros(3,28,28)\n",
    "\n",
    "torch.cat(\n",
    "    (\n",
    "        batch\n",
    "        ,torch.stack(\n",
    "            (t1,t2,t3)\n",
    "            ,dim=0\n",
    "        )\n",
    "    )\n",
    "    ,dim=0\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "batch = torch.zeros(3,3,28,28)\n",
    "t1 = torch.zeros(3,28,28)\n",
    "t2 = torch.zeros(3,28,28)\n",
    "t3 = torch.zeros(3,28,28)\n",
    "\n",
    "torch.cat(\n",
    "    (\n",
    "        batch\n",
    "        ,t1.unsqueeze(0)\n",
    "        ,t2.unsqueeze(0)\n",
    "        ,t3.unsqueeze(0)\n",
    "    )\n",
    "    ,dim=0\n",
    ").shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at torch.autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "torch.set_printoptions(linewidth=120) # Display options for output\n",
    "torch.set_grad_enabled(True) # Already on by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nn.Parameter(torch.ones(1,3))\n",
    "b = nn.Parameter(torch.tensor([1.,2,3]))\n",
    "c = a + b[0] * 2\n",
    "d = c.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop Run Builder - Neural Network Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from collections import namedtuple\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunBuilder():\n",
    "    @staticmethod\n",
    "    def get_runs(params):\n",
    "\n",
    "        Run = namedtuple('Run', params.keys())\n",
    "\n",
    "        runs = []\n",
    "        for v in product(*params.values()):\n",
    "            runs.append(Run(*v))\n",
    "\n",
    "        return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = OrderedDict(\n",
    "    lr = [.01, .001]\n",
    "    ,batch_size = [1000, 10000]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Run(lr=0.01, batch_size=1000),\n",
       " Run(lr=0.01, batch_size=10000),\n",
       " Run(lr=0.001, batch_size=1000),\n",
       " Run(lr=0.001, batch_size=10000)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = RunBuilder.get_runs(params)\n",
    "runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run(lr=0.01, batch_size=1000)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = runs[0]\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 1000\n"
     ]
    }
   ],
   "source": [
    "print(run.lr, run.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(lr=0.01, batch_size=1000) 0.01 1000\n",
      "Run(lr=0.01, batch_size=10000) 0.01 10000\n",
      "Run(lr=0.001, batch_size=1000) 0.001 1000\n",
      "Run(lr=0.001, batch_size=10000) 0.001 10000\n"
     ]
    }
   ],
   "source": [
    "for run in runs:\n",
    "    print(run, run.lr, run.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = OrderedDict(\n",
    "    lr = [.01, .001]\n",
    "    ,batch_size = [1000, 10000]\n",
    "    ,device = [\"cuda\", \"cpu\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Run(lr=0.01, batch_size=1000, device='cuda'),\n",
       " Run(lr=0.01, batch_size=1000, device='cpu'),\n",
       " Run(lr=0.01, batch_size=10000, device='cuda'),\n",
       " Run(lr=0.01, batch_size=10000, device='cpu'),\n",
       " Run(lr=0.001, batch_size=1000, device='cuda'),\n",
       " Run(lr=0.001, batch_size=1000, device='cpu'),\n",
       " Run(lr=0.001, batch_size=10000, device='cuda'),\n",
       " Run(lr=0.001, batch_size=10000, device='cpu')]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = RunBuilder.get_runs(params)\n",
    "runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to build the RunBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = OrderedDict(\n",
    "    lr = [.01, .001]\n",
    "    ,batch_size = [1000, 10000]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['lr', 'batch_size'])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_values([[0.01, 0.001], [1000, 10000]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "Run = namedtuple('Run', params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Run(lr=0.01, batch_size=1000),\n",
       " Run(lr=0.01, batch_size=10000),\n",
       " Run(lr=0.001, batch_size=1000),\n",
       " Run(lr=0.001, batch_size=10000)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = []\n",
    "for v in product(*params.values()):\n",
    "    runs.append(Run(*v))\n",
    "runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment:-Run(lr=0.01, batch_size=1000) lr=0.01, batch_size=1000\n",
      "comment:-Run(lr=0.01, batch_size=10000) lr=0.01, batch_size=10000\n",
      "comment:-Run(lr=0.001, batch_size=1000) lr=0.001, batch_size=1000\n",
      "comment:-Run(lr=0.001, batch_size=10000) lr=0.001, batch_size=10000\n"
     ]
    }
   ],
   "source": [
    "for run in RunBuilder.get_runs(params):\n",
    "    comment = f'-{run}'\n",
    "    print(f'comment:{comment} lr={run.lr}, batch_size={run.batch_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Training Loop Refactoring - Simultaneous Hyperparameter Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from IPython.display import display, clear_output\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "\n",
    "from itertools import product\n",
    "from collections import namedtuple\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "       \n",
    "        t = F.relu(self.conv1(t))\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        t = F.relu(self.conv2(t))\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        t = t.flatten(start_dim=1)\n",
    "        t = F.relu(self.fc1(t))\n",
    "        t = F.relu(self.fc2(t))\n",
    "        t = self.out(t)\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunBuilder():\n",
    "    @staticmethod\n",
    "    def get_runs(params):\n",
    "\n",
    "        Run = namedtuple('Run', params.keys())\n",
    "\n",
    "        runs = []\n",
    "        for v in product(*params.values()):\n",
    "            runs.append(Run(*v))\n",
    "\n",
    "        return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunManager():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.epoch_count = 0\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        self.epoch_start_time = None\n",
    "        \n",
    "        self.run_params = None\n",
    "        self.run_count = 0\n",
    "        self.run_data = []\n",
    "        self.run_start_time = None\n",
    "        \n",
    "        self.network = None\n",
    "        self.loader = None\n",
    "        self.tb = None\n",
    "        \n",
    "    def begin_run(self, run, network, loader):\n",
    "        \n",
    "        self.run_start_time = time.time()\n",
    "\n",
    "        self.run_params = run\n",
    "        self.run_count += 1\n",
    "        \n",
    "        self.network = network\n",
    "        self.loader = loader\n",
    "        self.tb = SummaryWriter(comment=f'-{run}')\n",
    "        \n",
    "        images, labels = next(iter(self.loader))\n",
    "        grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "        self.tb.add_image('images', grid)\n",
    "        self.tb.add_graph(self.network, images)\n",
    "        \n",
    "    def end_run(self):\n",
    "        self.tb.close()\n",
    "        self.epoch_count = 0   \n",
    "\n",
    "    def begin_epoch(self):\n",
    "        self.epoch_start_time = time.time()\n",
    "        \n",
    "        self.epoch_count += 1\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "\n",
    "    def end_epoch(self):\n",
    "        \n",
    "        epoch_duration = time.time() - self.epoch_start_time\n",
    "        run_duration = time.time() - self.run_start_time\n",
    "        \n",
    "        loss = self.epoch_loss / len(self.loader.dataset)\n",
    "        accuracy = self.epoch_num_correct / len(self.loader.dataset)\n",
    "                \n",
    "        self.tb.add_scalar('Loss', loss, self.epoch_count)\n",
    "        self.tb.add_scalar('Accuracy', accuracy, self.epoch_count)\n",
    "        \n",
    "        for name, param in self.network.named_parameters():\n",
    "            self.tb.add_histogram(name, param, self.epoch_count)\n",
    "            self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)\n",
    "        \n",
    "        results = OrderedDict()\n",
    "        results[\"run\"] = self.run_count\n",
    "        results[\"epoch\"] = self.epoch_count\n",
    "        results['loss'] = loss\n",
    "        results[\"accuracy\"] = accuracy\n",
    "        results['epoch duration'] = epoch_duration\n",
    "        results['run duration'] = run_duration\n",
    "        for k,v in self.run_params._asdict().items(): results[k] = v\n",
    "        self.run_data.append(results)\n",
    "        \n",
    "        df = pd.DataFrame.from_dict(self.run_data, orient='columns')\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        display(df)\n",
    "        \n",
    "    def track_loss(self, loss):\n",
    "        self.epoch_loss += loss.item() * self.loader.batch_size\n",
    "        \n",
    "    def track_num_correct(self, preds, labels):\n",
    "        self.epoch_num_correct += self._get_num_correct(preds, labels)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def _get_num_correct(self, preds, labels):\n",
    "        return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "    \n",
    "    def save(self, fileName):\n",
    "        \n",
    "        pd.DataFrame.from_dict(\n",
    "            self.run_data\n",
    "            ,orient='columns'\n",
    "        ).to_csv(f'{fileName}.csv')\n",
    "        \n",
    "        with open(f'{fileName}.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.run_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data'\n",
    "    ,train=True\n",
    "    ,download=True\n",
    "    ,transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>epoch duration</th>\n",
       "      <th>run duration</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>shuffle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.048481</td>\n",
       "      <td>0.597950</td>\n",
       "      <td>21.582150</td>\n",
       "      <td>22.269992</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.552703</td>\n",
       "      <td>0.782333</td>\n",
       "      <td>21.621635</td>\n",
       "      <td>43.975405</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.470257</td>\n",
       "      <td>0.820733</td>\n",
       "      <td>21.501475</td>\n",
       "      <td>65.561677</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.412907</td>\n",
       "      <td>0.847333</td>\n",
       "      <td>21.865842</td>\n",
       "      <td>87.515285</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.368734</td>\n",
       "      <td>0.865583</td>\n",
       "      <td>21.599631</td>\n",
       "      <td>109.197826</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.936397</td>\n",
       "      <td>0.640250</td>\n",
       "      <td>21.395359</td>\n",
       "      <td>22.045362</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.514760</td>\n",
       "      <td>0.802483</td>\n",
       "      <td>21.994951</td>\n",
       "      <td>44.125087</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.425505</td>\n",
       "      <td>0.843917</td>\n",
       "      <td>21.833435</td>\n",
       "      <td>66.045290</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.372440</td>\n",
       "      <td>0.863717</td>\n",
       "      <td>22.744391</td>\n",
       "      <td>88.875453</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.337898</td>\n",
       "      <td>0.875933</td>\n",
       "      <td>22.793767</td>\n",
       "      <td>111.766859</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.275311</td>\n",
       "      <td>0.510367</td>\n",
       "      <td>21.862379</td>\n",
       "      <td>23.251919</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.661353</td>\n",
       "      <td>0.742867</td>\n",
       "      <td>21.691654</td>\n",
       "      <td>45.028346</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.543441</td>\n",
       "      <td>0.790467</td>\n",
       "      <td>21.608143</td>\n",
       "      <td>66.738227</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.483308</td>\n",
       "      <td>0.816750</td>\n",
       "      <td>21.628441</td>\n",
       "      <td>88.456537</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.449077</td>\n",
       "      <td>0.833633</td>\n",
       "      <td>21.946581</td>\n",
       "      <td>110.493666</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.272752</td>\n",
       "      <td>0.521583</td>\n",
       "      <td>21.291116</td>\n",
       "      <td>22.517865</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.655807</td>\n",
       "      <td>0.738700</td>\n",
       "      <td>21.162097</td>\n",
       "      <td>43.765300</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.545546</td>\n",
       "      <td>0.788050</td>\n",
       "      <td>21.128133</td>\n",
       "      <td>64.984161</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.491936</td>\n",
       "      <td>0.815533</td>\n",
       "      <td>21.653679</td>\n",
       "      <td>86.732587</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.446435</td>\n",
       "      <td>0.836033</td>\n",
       "      <td>21.190235</td>\n",
       "      <td>108.011621</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    run  epoch      loss  accuracy  epoch duration  run duration    lr  \\\n",
       "0     1      1  1.048481  0.597950       21.582150     22.269992  0.01   \n",
       "1     1      2  0.552703  0.782333       21.621635     43.975405  0.01   \n",
       "2     1      3  0.470257  0.820733       21.501475     65.561677  0.01   \n",
       "3     1      4  0.412907  0.847333       21.865842     87.515285  0.01   \n",
       "4     1      5  0.368734  0.865583       21.599631    109.197826  0.01   \n",
       "5     2      1  0.936397  0.640250       21.395359     22.045362  0.01   \n",
       "6     2      2  0.514760  0.802483       21.994951     44.125087  0.01   \n",
       "7     2      3  0.425505  0.843917       21.833435     66.045290  0.01   \n",
       "8     2      4  0.372440  0.863717       22.744391     88.875453  0.01   \n",
       "9     2      5  0.337898  0.875933       22.793767    111.766859  0.01   \n",
       "10    3      1  1.275311  0.510367       21.862379     23.251919  0.01   \n",
       "11    3      2  0.661353  0.742867       21.691654     45.028346  0.01   \n",
       "12    3      3  0.543441  0.790467       21.608143     66.738227  0.01   \n",
       "13    3      4  0.483308  0.816750       21.628441     88.456537  0.01   \n",
       "14    3      5  0.449077  0.833633       21.946581    110.493666  0.01   \n",
       "15    4      1  1.272752  0.521583       21.291116     22.517865  0.01   \n",
       "16    4      2  0.655807  0.738700       21.162097     43.765300  0.01   \n",
       "17    4      3  0.545546  0.788050       21.128133     64.984161  0.01   \n",
       "18    4      4  0.491936  0.815533       21.653679     86.732587  0.01   \n",
       "19    4      5  0.446435  0.836033       21.190235    108.011621  0.01   \n",
       "\n",
       "    batch_size  shuffle  \n",
       "0         1000     True  \n",
       "1         1000     True  \n",
       "2         1000     True  \n",
       "3         1000     True  \n",
       "4         1000     True  \n",
       "5         1000    False  \n",
       "6         1000    False  \n",
       "7         1000    False  \n",
       "8         1000    False  \n",
       "9         1000    False  \n",
       "10        2000     True  \n",
       "11        2000     True  \n",
       "12        2000     True  \n",
       "13        2000     True  \n",
       "14        2000     True  \n",
       "15        2000    False  \n",
       "16        2000    False  \n",
       "17        2000    False  \n",
       "18        2000    False  \n",
       "19        2000    False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = OrderedDict(\n",
    "    lr = [.01]\n",
    "    ,batch_size = [1000, 2000]\n",
    "    ,shuffle = [True, False]\n",
    ")\n",
    "m = RunManager()\n",
    "for run in RunBuilder.get_runs(params):\n",
    "\n",
    "    network = Network()\n",
    "    loader = DataLoader(train_set, batch_size=run.batch_size, shuffle=run.shuffle)\n",
    "    optimizer = optim.Adam(network.parameters(), lr=run.lr)\n",
    "    \n",
    "    m.begin_run(run, network, loader)\n",
    "    for epoch in range(5):\n",
    "        m.begin_epoch()\n",
    "        for batch in loader:\n",
    "            \n",
    "            images, labels = batch\n",
    "            preds = network(images) # Pass Batch\n",
    "            loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
    "            optimizer.zero_grad() # Zero Gradients\n",
    "            loss.backward() # Calculate Gradients\n",
    "            optimizer.step() # Update Weights\n",
    "            \n",
    "            m.track_loss(loss)\n",
    "            m.track_num_correct(preds, labels)  \n",
    "        m.end_epoch()\n",
    "    m.end_run()\n",
    "m.save('results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch DataLoader num_workers Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>epoch duration</th>\n",
       "      <th>run duration</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>num_workers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.566253</td>\n",
       "      <td>0.782583</td>\n",
       "      <td>23.281029</td>\n",
       "      <td>23.374832</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.573350</td>\n",
       "      <td>0.783917</td>\n",
       "      <td>18.125359</td>\n",
       "      <td>18.965940</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.574852</td>\n",
       "      <td>0.782133</td>\n",
       "      <td>18.161020</td>\n",
       "      <td>19.037995</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.593246</td>\n",
       "      <td>0.775067</td>\n",
       "      <td>18.637056</td>\n",
       "      <td>19.669869</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.587598</td>\n",
       "      <td>0.777500</td>\n",
       "      <td>18.631994</td>\n",
       "      <td>20.123626</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.596401</td>\n",
       "      <td>0.775983</td>\n",
       "      <td>20.110439</td>\n",
       "      <td>22.930428</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.105825</td>\n",
       "      <td>0.577500</td>\n",
       "      <td>21.254815</td>\n",
       "      <td>21.941008</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1.013017</td>\n",
       "      <td>0.612267</td>\n",
       "      <td>15.961835</td>\n",
       "      <td>17.457127</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.881558</td>\n",
       "      <td>0.666200</td>\n",
       "      <td>16.060656</td>\n",
       "      <td>17.614599</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1.034153</td>\n",
       "      <td>0.606767</td>\n",
       "      <td>16.206196</td>\n",
       "      <td>17.883490</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.963817</td>\n",
       "      <td>0.626400</td>\n",
       "      <td>16.700765</td>\n",
       "      <td>18.882340</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1.046822</td>\n",
       "      <td>0.601683</td>\n",
       "      <td>17.912993</td>\n",
       "      <td>21.747298</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2.173913</td>\n",
       "      <td>0.265983</td>\n",
       "      <td>22.219368</td>\n",
       "      <td>27.145123</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2.156031</td>\n",
       "      <td>0.191167</td>\n",
       "      <td>16.563987</td>\n",
       "      <td>23.368729</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2.182048</td>\n",
       "      <td>0.210250</td>\n",
       "      <td>16.128202</td>\n",
       "      <td>23.030015</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2.245768</td>\n",
       "      <td>0.200683</td>\n",
       "      <td>16.248334</td>\n",
       "      <td>22.108252</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2.177970</td>\n",
       "      <td>0.206483</td>\n",
       "      <td>16.921782</td>\n",
       "      <td>23.897321</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2.153342</td>\n",
       "      <td>0.208017</td>\n",
       "      <td>18.555999</td>\n",
       "      <td>26.654219</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10000</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    run  epoch      loss  accuracy  epoch duration  run duration    lr  \\\n",
       "0     1      1  0.566253  0.782583       23.281029     23.374832  0.01   \n",
       "1     2      1  0.573350  0.783917       18.125359     18.965940  0.01   \n",
       "2     3      1  0.574852  0.782133       18.161020     19.037995  0.01   \n",
       "3     4      1  0.593246  0.775067       18.637056     19.669869  0.01   \n",
       "4     5      1  0.587598  0.777500       18.631994     20.123626  0.01   \n",
       "5     6      1  0.596401  0.775983       20.110439     22.930428  0.01   \n",
       "6     7      1  1.105825  0.577500       21.254815     21.941008  0.01   \n",
       "7     8      1  1.013017  0.612267       15.961835     17.457127  0.01   \n",
       "8     9      1  0.881558  0.666200       16.060656     17.614599  0.01   \n",
       "9    10      1  1.034153  0.606767       16.206196     17.883490  0.01   \n",
       "10   11      1  0.963817  0.626400       16.700765     18.882340  0.01   \n",
       "11   12      1  1.046822  0.601683       17.912993     21.747298  0.01   \n",
       "12   13      1  2.173913  0.265983       22.219368     27.145123  0.01   \n",
       "13   14      1  2.156031  0.191167       16.563987     23.368729  0.01   \n",
       "14   15      1  2.182048  0.210250       16.128202     23.030015  0.01   \n",
       "15   16      1  2.245768  0.200683       16.248334     22.108252  0.01   \n",
       "16   17      1  2.177970  0.206483       16.921782     23.897321  0.01   \n",
       "17   18      1  2.153342  0.208017       18.555999     26.654219  0.01   \n",
       "\n",
       "    batch_size  num_workers  \n",
       "0          100            0  \n",
       "1          100            1  \n",
       "2          100            2  \n",
       "3          100            4  \n",
       "4          100            8  \n",
       "5          100           16  \n",
       "6         1000            0  \n",
       "7         1000            1  \n",
       "8         1000            2  \n",
       "9         1000            4  \n",
       "10        1000            8  \n",
       "11        1000           16  \n",
       "12       10000            0  \n",
       "13       10000            1  \n",
       "14       10000            2  \n",
       "15       10000            4  \n",
       "16       10000            8  \n",
       "17       10000           16  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = OrderedDict(\n",
    "    lr = [.01]\n",
    "    ,batch_size = [100, 1000, 10000]\n",
    "    ,num_workers = [0, 1, 2, 4, 8, 16]\n",
    "    #,shuffle = [True, False]\n",
    ")\n",
    "m = RunManager()\n",
    "for run in RunBuilder.get_runs(params):\n",
    "\n",
    "    network = Network()\n",
    "    loader = DataLoader(train_set, batch_size=run.batch_size, num_workers=run.num_workers)\n",
    "    optimizer = optim.Adam(network.parameters(), lr=run.lr)\n",
    "    \n",
    "    m.begin_run(run, network, loader)\n",
    "    for epoch in range(1):\n",
    "        m.begin_epoch()\n",
    "        for batch in loader:\n",
    "            \n",
    "            images, labels = batch\n",
    "            preds = network(images) # Pass Batch\n",
    "            loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
    "            optimizer.zero_grad() # Zero Gradients\n",
    "            loss.backward() # Calculate Gradients\n",
    "            optimizer.step() # Update Weights\n",
    "            \n",
    "            m.track_loss(loss)\n",
    "            m.track_num_correct(preds, labels)  \n",
    "        m.end_epoch()\n",
    "    m.end_run()\n",
    "m.save('results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
